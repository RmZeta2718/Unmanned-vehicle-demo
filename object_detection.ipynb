{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实时物体跟踪 例子 \n",
    " \n",
    "在这个 notebook 中，我们会展示如何使用 JetBot 跟踪对象。我们将使用在 [COCO dataset](http://cocodataset.org) 网站上预先训练好的神经网络，以检测90种不同的常见对象。例如包括了\n",
    "\n",
    "* 人 (index 0)\n",
    "* 杯子 (index 47)\n",
    " \n",
    "和许多其他的常见对象。你可以点击 [这里查看](https://github.com/tensorflow/models/blob/master/research/object_detection/data/mscoco_complete_label_map.pbtxt) 所有的对象。\n",
    "\n",
    "该模型来自 [TensorFlow 对象检测 API](https://github.com/tensorflow/models/tree/master/research/object_detection)，它还提供自定义训练任务，当训练完成，我们就能使用 Jetson Nano 上的 NVIDIA TensorRT 对其进行优化。\n",
    "\n",
    "这样做使得这个神经网络非常快，能在 Jetson 上实时执行。但是，这 notebook 并不包含所说的训练与优化步骤。\n",
    "  \n",
    "无论如何，让我们开始吧。首先，我们要导入``ObjectDetector``类，它采用我们预先训练过的SSD引擎。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算单个摄像头图像的信号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import ObjectDetector\n",
    "\n",
    "model = ObjectDetector('ssd_mobilenet_v2_coco.engine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在内部，``ObjectDetector``类使用 TensorRT Python API执行我们提供的引擎。\n",
    "  \n",
    "它还负责预处理神经网络的输入，以及分析检测到的对象。\n",
    "\n",
    "现在这只适用于``jetbot.ssd_tensorrt``package创建的引擎。该软件包具有转换阻最佳的TensorFlow对象模型给TensorRT引擎\n",
    "\n",
    "接下来，让我们初始化我们的相机。我需要300x300的图像像素作为输入。所以，我们需要设置我们的摄像头。\n",
    " \n",
    "> 在内部，Jetson Nano的图像信号处理是使用Carmera类的GStreamer实现的。这是超级快速的方式，大大地减少了CPU的计算量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Camera\n",
    "\n",
    "camera = Camera.instance(width=300, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，让我们使用一些摄像头输入执行我们的神经网络。默认情况下``ObjectDetector`` 类生成 ``bgr8``格式。然而，如果你想使用不同的格式作为输入，则你可以覆盖默认的预处理功能。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jetbot.object_detection.ObjectDetector at 0x7f9af94278>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 1, 'confidence': 0.9596109390258789, 'bbox': [0.0071196407079696655, 0.06254974007606506, 0.31206566095352173, 0.9844751358032227]}, {'label': 32, 'confidence': 0.6048657894134521, 'bbox': [0.5587514042854309, 0.018432646989822388, 0.9849312901496887, 0.9875426292419434]}]]\n"
     ]
    }
   ],
   "source": [
    "detections = model(camera.value)\n",
    "\n",
    "print(detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果摄像头的视野中又任何COCO对象时，它们会存储在``detections``变量中。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示检测对象的名称\n",
    "\n",
    "我们将使用下面的代码打印出检测到的对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3caf4a1ffb704b89a2b1ed752e1d242a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value=\"[[{'label': 80, 'confidence': 0.39793840050697327, 'bbox': [0.5121945142745972, 0.324544668197…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "\n",
    "detections_widget = widgets.Textarea()\n",
    "\n",
    "detections_widget.value = str(detections)\n",
    "\n",
    "display(detections_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你应该看到每个图像中检测到的每个标签，相似度和边界框。但在这个例子只有一个图像。\n",
    "\n",
    "\n",
    "要打印第一个图像中检测到的第一个对象，我们可以调用一下内容\n",
    "\n",
    "> 如果未检测到任何对象，则可能会抛出错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d4fe2e9fa404dedabccbd20a365b61d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='300', width='300')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from jetbot import bgr8_to_jpeg\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "image = widgets.Image(format='jpeg', width=300, height=300)\n",
    "\n",
    "display(image)\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 80, 'confidence': 0.39793840050697327, 'bbox': [0.5121945142745972, 0.32454466819763184, 0.9830870628356934, 0.7929606437683105]}\n"
     ]
    }
   ],
   "source": [
    "image_number = 0\n",
    "object_number = 0\n",
    "\n",
    "print(detections[image_number][object_number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 控制Jetbot去跟踪中心目标\n",
    "\n",
    "现在我们希望我们的JetBot能跟随指定的对象。 为此，我们将执行以下操作\n",
    "\n",
    "1. 检测与指定匹配的对象\n",
    "\n",
    "2. 选择最接近摄像机视野中心的物体，就是 \"目标\" 对象\n",
    "\n",
    "3. 将机器人转向目标物体，否则徘徊\n",
    "\n",
    "4. 如果我们被障碍物阻挡，则左转  \n",
    "      \n",
    "我们也会创建一些部件，例如用于显示目标对象的标签，JetBot当前的速度和转弯提示。它将根据目标物体之间的距离，控制JetBot转动的速度和摄像头视野的中心。\n",
    "\n",
    "首先，让我们加载我们的碰撞检测模型。 \n",
    "为了方便，预先训练的模型也存储在此目录中，但如果你已经训练过避障模型，那你也可以使用该模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "collision_model = torchvision.models.alexnet(pretrained=False)\n",
    "collision_model.classifier[6] = torch.nn.Linear(collision_model.classifier[6].in_features, 2)\n",
    "collision_model.load_state_dict(torch.load('best_model.pth'))\n",
    "device = torch.device('cuda')\n",
    "collision_model = collision_model.to(device)\n",
    "\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.resize(x, (224, 224))\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "太好了，现在初始化JetBot，这样我们就可以控制JetBot的电机了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，让我们显示所有的控件在网络上执行代码更新摄像头。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e2f837852a4b07918d870d79efa49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from jetbot import bgr8_to_jpeg\n",
    "import numpy as np\n",
    "blocked_widget = widgets.FloatSlider(min=0.0, max=1.0, value=0.0, description='blocked')\n",
    "image_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "label_widget = widgets.IntText(value=1, description='tracked label')\n",
    "speed_widget = widgets.FloatSlider(value=0.4, min=0.0, max=1.0, description='speed')\n",
    "turn_gain_widget = widgets.FloatSlider(value=0.8, min=0.0, max=2.0, description='turn gain')\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([image_widget, blocked_widget]),\n",
    "    label_widget,\n",
    "    speed_widget,\n",
    "    turn_gain_widget\n",
    "]))\n",
    "\n",
    "width = int(image_widget.width)\n",
    "height = int(image_widget.height)\n",
    "\n",
    "def detection_center(detection):\n",
    "    \"\"\"计算目标的xy中心坐标\"\"\"\n",
    "    bbox = detection['bbox']\n",
    "    center_x = (bbox[0] + bbox[2]) / 2.0 - 0.5\n",
    "    center_y = (bbox[1] + bbox[3]) / 2.0 - 0.5\n",
    "    return (center_x, center_y)\n",
    "    \n",
    "def norm(vec):\n",
    "    \"\"\"计算2D向量长度\"\"\"\n",
    "    return np.sqrt(vec[0]**2 + vec[1]**2)\n",
    "\n",
    "def closest_detection(detections):\n",
    "    \"\"\"找出离图像中心最近的目标\"\"\"\n",
    "    closest_detection = None\n",
    "    for det in detections:\n",
    "        center = detection_center(det)\n",
    "        if closest_detection is None:\n",
    "            closest_detection = det\n",
    "        elif norm(detection_center(det)) < norm(detection_center(closest_detection)):\n",
    "            closest_detection = det\n",
    "    return closest_detection\n",
    "        \n",
    "def dist(v0, v1):\n",
    "    return np.dot(v0, v1) / np.sqrt(np.dot(v0, v0)) / np.sqrt(np.dot(v1, v1))\n",
    "\n",
    "def execute(change):\n",
    "    image = change['new']\n",
    "    \n",
    "    # 计算所有被检测到的目标\n",
    "    detections = model(image)\n",
    "    \n",
    "#     x0, y0, x1, y1 = 200, 0, 200, 10\n",
    "    x0, y0, x1, y1 = change['line']\n",
    "    w, h  = image.shape[0], image.shape[1]\n",
    "#     print(w, h)\n",
    "    cv2.line(image, (x0, y0), (x1, y1), (255,0,0), 10)\n",
    "    x0 /= w\n",
    "    y0 /= h\n",
    "    x1 /= w\n",
    "    y1 /= h\n",
    "    \n",
    "    closest_detection = None\n",
    "    for det in detections[0]:\n",
    "        if det['label'] == 1:\n",
    "            continue;\n",
    "        bbox = det['bbox']\n",
    "        cv2.rectangle(image, (int(width * bbox[0]), int(height * bbox[1])), (int(width * bbox[2]), int(height * bbox[3])), (255, 0, 0), 2)\n",
    "\n",
    "        center_x = (bbox[0] + bbox[2]) / 2.0 - 0.5\n",
    "        center_y = (bbox[1] + bbox[3]) / 2.0 - 0.5\n",
    "#         print(center_x, center_y)\n",
    "        dis =  dist(np.array([x1-x0, y1-y0]), np.array([center_x - x0, center_y - y0]))\n",
    "        if closest_detection is None:\n",
    "            closest_detection = det\n",
    "        else:\n",
    "            \n",
    "            xx, yy = detection_center(closest_detection)\n",
    "            if dis < dist(np.array([x1-x0, y1-y0]), np.array([xx - x0, yy - y0])):\n",
    "                closest_detection = det\n",
    "        \n",
    "    if closest_detection is None:\n",
    "        label_widget.value = 1\n",
    "#         print(\"------\")\n",
    "    else:\n",
    "        label_widget.value = closest_detection['label']\n",
    "        \n",
    "        bbox = closest_detection['bbox']\n",
    "        cv2.rectangle(image, (int(width * bbox[0]), int(height * bbox[1])), (int(width * bbox[2]), int(height * bbox[3])), (0, 255, 0), 5)\n",
    "        \n",
    "    # 更新图像小部件\n",
    "    image_widget.value = bgr8_to_jpeg(image)\n",
    "# execute({'new': camera.value})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用下面的代码，将执行功能连接到每帧图像更新。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve_all()\n",
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "真棒！ 如果机器人未被阻挡，您应该看到在检测到的物体周围用蓝色绘制的框。 目标对象（JetBot设置的对象）将以绿色显示。\n",
    "\n",
    "检测到对象应该朝向目标转向。 如果它被一个物体挡住，那么它就会向左转。\n",
    "\n",
    "您可以调用下面的代码，断开相机的处理并停止机器人。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "camera.unobserve_all()\n",
    "time.sleep(1.0)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
